{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqfcxkMTcd02"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "import keras.backend as K\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError as rmse\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def MOUNT():\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "wDNJdx_WciW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NewTimeStampDataframe(df,time):\n",
        "  df.rename(columns={'Days' : 'timestamp', 'Open' : 'open', \n",
        "                    'High' : 'high', 'Low' : 'low', 'Close' : 'close'}, inplace=True)\n",
        "  df['timestamp'] = pd.to_datetime(df['timestamp'], infer_datetime_format=True)\n",
        "  df.set_index('timestamp', inplace=True)\n",
        " \n",
        "  df = df.groupby(pd.Grouper(freq=time)).agg({\"open\": \"first\", \n",
        "                                              \"close\": \"last\", \n",
        "                                              \"low\": \"min\", \n",
        "                                              \"high\": \"max\"})\n",
        "  df.columns = [\"open\", \"close\", \"low\", \"high\"]\n",
        "  return df"
      ],
      "metadata": {
        "id": "KfYDbdT2crWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def AddingColumn(df):\n",
        "  df['previous_close'] = df['close'].shift(-1)\n",
        "  df['hour'] = df.index.hour\n",
        "  df['day']  = df.index.weekday\n",
        "  df['week'] = df.index.week\n",
        "  #df['dayofweek']=df.index.dayofweek\n",
        "  #df['quarter']=df.index.quarter\n",
        "  #df['month']=df.index.month\n",
        "  #df['year']=df.index.year\n",
        "  #df['dayofyear']=df.index.dayofyear\n",
        "  \n",
        "  df['momentum']  = (df['open'] - df['close'])\n",
        "  df['avg_price'] = (df['low'] + df['high'])/2\n",
        "  df['range']     = df['high'] - df['low']\n",
        "  df['ohlc_price'] = (df['low'] + df['high'] + df['open'] + df['close'])/4\n",
        "  df.dropna(inplace=True)\n",
        "  return df"
      ],
      "metadata": {
        "id": "2FFOBO6Qc81w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ApplyPCA(ndf):\n",
        "  from sklearn.decomposition import PCA\n",
        "\n",
        "  Dataset = ndf.copy().values.astype('float32') # D_S = Dataset\n",
        "  pca_features = ndf.columns.tolist()\n",
        "\n",
        "  pca = PCA(n_components=1)\n",
        "  ndf['pca'] = pca.fit_transform(Dataset)\n",
        "  return ndf"
      ],
      "metadata": {
        "id": "F8Fhz-z6djjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_numpy_array_features(x_train, x_val, x_test, window_size):\n",
        "  \n",
        "  xtrain = []\n",
        "  xval = []\n",
        "  xtest = []\n",
        "\n",
        "  for i in range(len(x_train)-window_size-1):\n",
        "    \n",
        "    train_row = x_train[i:i+window_size]\n",
        "   \n",
        "    xtrain.append(train_row)\n",
        "  \n",
        "  for i in range(len(x_val)-window_size-1):\n",
        "    \n",
        "    val_row = x_val[i:i+window_size]\n",
        "   \n",
        "    xval.append(val_row)\n",
        "\n",
        "  for i in range(len(x_test)-window_size-1):\n",
        "    \n",
        "    test_row = x_test[i:i+window_size]\n",
        "   \n",
        "    xtest.append(test_row)\n",
        "  return np.array(xtrain), np.array(xval), np.array(xtest)"
      ],
      "metadata": {
        "id": "ayssiYbzqbpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_numpy_array_target(y_train, y_val, y_test, window_size):\n",
        "  \n",
        "  \n",
        "  ytrain = []\n",
        "  yval = []\n",
        "  ytest = [] \n",
        "  for i in range(len(y_train)-window_size-1):\n",
        "    \n",
        "    train_label = y_train[i+window_size]\n",
        "    ytrain.append(train_label)\n",
        "\n",
        "  for i in range(len(y_val)-window_size-1):\n",
        "    \n",
        "    val_label = y_val[i+window_size]\n",
        "    yval.append(val_label)\n",
        "\n",
        "  for i in range(len(y_test)-window_size-1):\n",
        "    \n",
        "    test_label = y_test[i+window_size]\n",
        "    ytest.append(test_label)\n",
        "    \n",
        "  return  np.array(ytrain), np.array(yval), np.array(ytest)"
      ],
      "metadata": {
        "id": "0Kl-Y-XlqwHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def df_to_X_y(df, window_size):\n",
        "  \n",
        "  X = []\n",
        "  y = []\n",
        "  for i in range(len(df)-window_size-1):\n",
        "    row = df[i:i+window_size]\n",
        "    X.append(row)\n",
        "    label = df[i+window_size]\n",
        "    y.append(label)\n",
        "    \n",
        "  return np.array(X), np.array(y)"
      ],
      "metadata": {
        "id": "8pep4dUZep6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def NormalizeDataset(Dataset):\n",
        "  #print(\"Before Normalization\")\n",
        "  #print(\"Min:\", np.min(Dataset))\n",
        "  #print(\"Max:\", np.max(Dataset))\n",
        "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "  Dataset = scaler.fit_transform(Dataset)\n",
        "  #print(\"After Normalization\")\n",
        "  #print(\"Min:\", np.min(Dataset))\n",
        "  #print(\"Max:\", np.max(Dataset))\n",
        "  return Dataset"
      ],
      "metadata": {
        "id": "j7ZCbPdmf9Bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Val_Test_split_60_40(X1,y1):\n",
        "  # Define the split time\n",
        "  train_split = int(len(X1) * 0.60)\n",
        "  test_split = int(len(X1) * 0.20)\n",
        "\n",
        "  # Get the train set \n",
        "  x_train = X1[:train_split]\n",
        "  y_train = y1[:train_split]\n",
        "  x_val= X1[train_split:(train_split + test_split)]\n",
        "  y_val= y1[train_split:(train_split + test_split)]\n",
        "            \n",
        "  # Get the validation set\n",
        "  x_test = X1[(train_split + test_split):]\n",
        "  y_test = y1[(train_split + test_split):]\n",
        "  print(len(x_train))\n",
        "  print(len(y_train))\n",
        "  print(len(x_val))\n",
        "  print(len(y_val))\n",
        "  print(len(x_test))\n",
        "  print(len(y_test))\n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "metadata": {
        "id": "4tzcWyEJMeO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Val_Test_split_70_30(X1,y1):\n",
        "  # Define the split time\n",
        "  train_split = int(len(X1) * 0.70)\n",
        "  test_split = int(len(X1) * 0.15)\n",
        "\n",
        "  # Get the train set \n",
        "  x_train = X1[:train_split]\n",
        "  y_train = y1[:train_split]\n",
        "  x_val= X1[train_split:(train_split + test_split)]\n",
        "  y_val= y1[train_split:(train_split + test_split)]\n",
        "            \n",
        "  # Get the validation set\n",
        "  x_test = X1[(train_split + test_split):]\n",
        "  y_test = y1[(train_split + test_split):]\n",
        "  print(len(x_train))\n",
        "  print(len(y_train))\n",
        "  print(len(x_val))\n",
        "  print(len(y_val))\n",
        "  print(len(x_test))\n",
        "  print(len(y_test))\n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "metadata": {
        "id": "0XDslQkZhV1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Val_Test_split_80_20(X1,y1):\n",
        "  # Define the split time\n",
        "  train_split = int(len(X1) * 0.80)\n",
        "  test_split = int(len(X1) * 0.20)\n",
        "\n",
        "  # Get the train set \n",
        "  x_train = X1[:train_split]\n",
        "  y_train = y1[:train_split]\n",
        "  x_val= X1[train_split:(train_split + test_split)]\n",
        "  y_val= y1[train_split:(train_split + test_split)]\n",
        "            \n",
        "  # Get the validation set\n",
        "  x_test = X1[(train_split + test_split):]\n",
        "  y_test = y1[(train_split + test_split):]\n",
        "  print(len(x_train))\n",
        "  print(len(y_train))\n",
        "  print(len(x_val))\n",
        "  print(len(y_val))\n",
        "  print(len(x_test))\n",
        "  print(len(y_test))\n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "metadata": {
        "id": "jju3X14nMrjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Train_Val_Test_split_15Min(X1,y1):\n",
        "  # Define the split time\n",
        "  split_time = int(len(X1) * 0.80)\n",
        "\n",
        "  # Get the train set \n",
        "  x_train = X1[:split_time]\n",
        "  y_train = y1[:split_time]\n",
        "  x_val= X1[split_time:(split_time+7500)]\n",
        "  y_val= y1[split_time:(split_time+7500)]\n",
        "            \n",
        "  # Get the validation set\n",
        "  x_test = X1[(split_time+7500):]\n",
        "  y_test = y1[(split_time+7500):]\n",
        "  print(len(x_train))\n",
        "  print(len(y_train))\n",
        "  print(len(x_val))\n",
        "  print(len(y_val))\n",
        "  print(len(x_test))\n",
        "  print(len(y_test))\n",
        "  return x_train, y_train, x_val, y_val, x_test, y_test"
      ],
      "metadata": {
        "id": "J6N-bYuNswBy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_LSTM_Model(X1):\n",
        "    model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=64, kernel_size=3,\n",
        "                        strides=1,\n",
        "                        activation=\"relu\",\n",
        "                        padding='causal',\n",
        "                        input_shape=[X1.shape[1], X1.shape[2]]),\n",
        "    \n",
        "\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "gQcXe_uqiudE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreateHistory(x_train, y_train, x_val, y_val, model, callbacks_list, Epochs, Batch_size):\n",
        "\n",
        "  model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mae', 'mse', rmse(),'mape'])\n",
        "  history = model.fit(x_train,y_train, epochs=Epochs, batch_size=Batch_size, verbose=1, callbacks=callbacks_list, validation_data=(x_val, y_val))\n",
        "  return history"
      ],
      "metadata": {
        "id": "zil2owaSkXx-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def R_Squared_Score(model, x, y):\n",
        "  from sklearn.metrics import r2_score as r2\n",
        "  y_pred = model.predict(x)\n",
        "\n",
        "  # Compute the R^2 score\n",
        "  r_squared = r2(y, y_pred)\n",
        "  return r_squared"
      ],
      "metadata": {
        "id": "Qoy3Ntj5EIBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RJLVNnhnFwzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SummarizeHistory(history):  \n",
        "  epoch = len(history.history['loss'])\n",
        "  for k in list(history.history.keys()):\n",
        "      if 'val' not in k:\n",
        "        plt.figure(figsize=(40,10))\n",
        "        plt.plot(history.history[k])\n",
        "        #plt.plot(history.history['val_' + k])\n",
        "        plt.title(k)\n",
        "        plt.ylabel(k)\n",
        "        plt.xlabel('epoch')\n",
        "        plt.legend(['train', 'test'], loc='upper left')\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "l-E7xUzRmLxI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(model, epoch):\n",
        "    from keras.callbacks import LearningRateScheduler\n",
        "    import keras.backend as K\n",
        "    if epoch%2==0 and epoch!=0:\n",
        "        lr = K.get_value(model.optimizer.lr)\n",
        "        K.set_value(model.optimizer.lr, lr*.9)\n",
        "        print(\"lr changed to {}\".format(lr*.9))\n",
        "    return K.get_value(model.optimizer.lr)"
      ],
      "metadata": {
        "id": "vMYhSOCYovSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CreatPrediction(model,x, y):\n",
        "  pred = model.predict(x)\n",
        "\n",
        "  predictions = pd.DataFrame()\n",
        "  predictions['predicted'] = pd.Series(np.reshape(pred, (pred.shape[0])))\n",
        "  predictions['actual'] = y\n",
        "  predictions = predictions.astype(float)\n",
        "  predictions.plot(figsize=(20,10))\n",
        "  plt.show()\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "l-KmLCCGuJSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JsdOKJBSv-JQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GRU_LSTM_Model(X1):\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.GRU(32,\n",
        "                        input_shape=[X1.shape[1], X1.shape[2]],return_sequences=True),\n",
        "    tf.keras.layers.LSTM(256, return_sequences=True),\n",
        "    \n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(64),\n",
        "    \n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "d4wtSi3bsJdV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_GRU_Model(X1):\n",
        "  model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=64, kernel_size=3,\n",
        "                      strides=1,\n",
        "                      activation=\"relu\",\n",
        "                      padding='causal',\n",
        "                      input_shape=[X1.shape[1], X1.shape[2]]),\n",
        "    tf.keras.layers.GRU(256, return_sequences=True),\n",
        "    \n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.GRU(64),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "  ])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "3gw2KTLTt7QX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GRU_Model(X1):\n",
        "  model = tf.keras.models.Sequential([\n",
        "                      \n",
        "    tf.keras.layers.GRU(256, input_shape=[X1.shape[1], X1.shape[2]], return_sequences=True),\n",
        "    \n",
        "    tf.keras.layers.GRU(64, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.GRU(16),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "jXgxuWSfexDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_Model(X1):\n",
        "  model = tf.keras.models.Sequential([\n",
        "                      \n",
        "    tf.keras.layers.LSTM(256, input_shape=[X1.shape[1], X1.shape[2]], return_sequences=True),\n",
        "    \n",
        "    tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.LSTM(16),\n",
        "\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "  ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "kXz5i0Z8iwQs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_BiLSTM_Model(X1):\n",
        "\n",
        "  model= tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=64, kernel_size=3,\n",
        "                      strides=1,\n",
        "                      activation=\"relu\",\n",
        "                      padding='causal',\n",
        "                      input_shape=[X1.shape[1], X1.shape[2]]),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "    \n",
        "    ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "snUbQjiwjc6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def GRU_BiLSTM_Model(X1):\n",
        "\n",
        "  model= tf.keras.models.Sequential([\n",
        "    tf.keras.layers.GRU(32,\n",
        "                        input_shape=[X1.shape[1], X1.shape[2]],return_sequences=True),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256, return_sequences=True)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "    \n",
        "    ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "h6-T1cNpm05-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def BiLSTM_Model(X1):\n",
        "\n",
        "  model= tf.keras.models.Sequential([\n",
        "\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, input_shape=[X1.shape[1], X1.shape[2]], return_sequences=True)),\n",
        "    \n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16)),\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "    \n",
        "    ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "RD6YiIZnnoIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_Model(X1):\n",
        "\n",
        "  model= tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv1D(filters=32, kernel_size=3,\n",
        "                      strides=1,\n",
        "                      activation=\"relu\",\n",
        "                      padding='causal',\n",
        "                      input_shape=[X1.shape[1], X1.shape[2]]),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "\n",
        "    tf.keras.layers.Conv1D(64, kernel_size=3, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling1D(pool_size=2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(16, activation=\"relu\"),\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid'),\n",
        "    tf.keras.layers.Lambda(lambda x: x * 400)\n",
        "    ])\n",
        "  return model"
      ],
      "metadata": {
        "id": "UgV2rN1vphb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "HHul7pCchU0h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7IPRrja-eo35"
      }
    }
  ]
}